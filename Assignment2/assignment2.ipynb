{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Fairness, Accountability and Ethics\n",
    "## Assignment 2\n",
    "Kamil Kojs, Janos Mate, Jorge del Pozo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, BasicProblem, generate_categories\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, \\\n",
    "                                confusion_matrix,  accuracy_score, precision_score, \\\n",
    "                                    recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "import scipy\n",
    "from scipy.optimize import fmin_tnc\n",
    "import math\n",
    "import os\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "except:\n",
    "    print(\"Run without Seaborn\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess the data\n",
    "We are going to work with the [Folktables](https://github.com/socialfoundations/folktables#quick-start-examples) dataset (*you have already worked with it*).\n",
    "\n",
    "1. As last week, we are still predicting the *Total person's income*  (I've digitized  it in  `target_transform=lambda x: x > 25000`).\n",
    "2. Today, we are going to implement two methods for data debiasing: [Fair PCA](https://deepai.org/publication/efficient-fair-pca-for-fair-representation-learning) and [A Geometric Solution to Fair Representations](https://dl.acm.org/doi/10.1145/3375627.3375864).\n",
    "3. We are going to evaluate the performance on two sensitive features: `SEX` (i.e. *Males* and *Females*) and `RAC1P` (we will consider only *Whites* and *African-Americans*)\n",
    "4. I updated the filtering method `adult_filter` to keep the specified groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(\n",
    "    survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "mm_scalar = MinMaxScaler()\n",
    "\n",
    "\n",
    "def adult_filter(data):\n",
    "    \"\"\"Mimic the filters in place for Adult data.\n",
    "    Adult documentation notes: Extraction was done by Barry Becker from\n",
    "    the 1994 Census database. A set of reasonably clean records was extracted\n",
    "    using the following conditions:\n",
    "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    df = df[df[\"RAC1P\"] < 3]  # keep only Whites and African-Americans\n",
    "    return df\n",
    "\n",
    "\n",
    "ACSIncomeNew = BasicProblem(\n",
    "    features=[\n",
    "        'AGEP',\n",
    "        'COW',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        'CIT',\n",
    "        'RELP',\n",
    "        'WKHP',\n",
    "        'PWGTP',\n",
    "        'SEX',\n",
    "        'RAC1P'\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,\n",
    "    group=['SEX', \"RAC1P\"],\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Bias Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the task 1 we should use data, which is not hot-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(\n",
    "    features=ACSIncomeNew.features, definition_df=definition_df)\n",
    "\n",
    "features_for_analysis, labels_for_analysis, groups_for_analysis = ACSIncomeNew.df_to_pandas(\n",
    "    acs_data, categories=categories)\n",
    "features_for_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(features, labels, groups, N=20000):\n",
    "\n",
    "    X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "        features.values, labels.values.reshape(-1), groups, test_size=0.3, random_state=0, shuffle=True)\n",
    "\n",
    "    N = 20000  # Subsampling due to speed\n",
    "\n",
    "    X_train = X_train[:N]\n",
    "    y_train = y_train[:N]\n",
    "    group_train = group_train[:N]\n",
    "    X_test = X_test[:N]\n",
    "    y_test = y_test[:N]\n",
    "    group_test = group_test[:N]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, group_train, group_test\n",
    "\n",
    "X_train_for_analysis, X_test_for_analysis, y_train_for_analysis, y_test_for_analysis, group_train_for_analysis, group_test_for_analysis = split_dataset(\n",
    "    features_for_analysis, labels_for_analysis, groups_for_analysis, N=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_analyses = pd.DataFrame({'AGEP': X_train_for_analysis[:, 0], 'COW': X_train_for_analysis[:, 1], \n",
    "                       'SCHL': X_train_for_analysis[:, 2], 'MAR': X_train_for_analysis[:, 3], 'CIT': X_train_for_analysis[:, 4], 'RELP': X_train_for_analysis[:, 5],\n",
    "                       'WKHP': X_train_for_analysis[:, 6], 'PWGTP': X_train_for_analysis[:, 7], 'SEX': X_train_for_analysis[:, 8],\n",
    "                        'RAC1P': X_train_for_analysis[:, 9]})\n",
    "dataset_for_analyses['PINCP'] = y_train_for_analysis.tolist()\n",
    "dataset_for_analyses.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1.: Data Collection and Representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Discuss sources of bias in the dataset and in the selected features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(dataset_for_analyses, x=\"AGEP\", bins=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(dataset_for_analyses, x=\"WKHP\", bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(dataset_for_analyses, x=\"PWGTP\", bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for col in dataset_for_analyses[[\"COW\", \"SCHL\", \"MAR\", \"CIT\", \"RELP\", \"SEX\", \"RAC1P\", \"PINCP\"]]:\n",
    "    plt.figure().set_figwidth(15)\n",
    "    dataset_for_analyses[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f\"Value counts for {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "#from 1994"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cover the following aspect: Training Data (refer to the Lecture 5 Slide #56: How to handle bias?**\n",
    "\n",
    "Training data is the data used to train machine learning algorithms and models. If the training data is biased against protected classes, then the resulting models and algorithms may perpetuate that bias and systematically disadvantage those classes.\n",
    "\n",
    "For example, consider a facial recognition algorithm that is trained on a dataset that is predominantly made up of images of white individuals. If the algorithm is then used to identify faces of individuals from other racial or ethnic groups, it may not perform as well and may have higher rates of false positives or false negatives for those groups. This could result in individuals from those groups being wrongly identified or excluded from certain opportunities, such as access to public services or employment.\n",
    "\n",
    "Another example is a language model that is trained on text from a specific demographic group or culture. If the model is then used to generate text or make predictions for individuals from other groups, it may not accurately capture their language or cultural nuances, resulting in biased or inappropriate outputs.\n",
    "\n",
    "To address these issues, it is important to ensure that training data is diverse and representative of all relevant groups. This can involve collecting additional data, using data augmentation techniques, or pre-processing the data to remove or balance any biases. Additionally, it is important to regularly evaluate the performance of models and algorithms to identify and address any biases that may have been introduced through the training data.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.: Proxies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Look at feature distributions if you split them by SEX groups (for Males and Females, separately).\n",
    "Do you see any potential sources of bias? Provide arguments.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['AGEP', 'WKHP', 'PWGTP']:\n",
    "    #sns.catplot(data=dataset_for_analyses, y=col, hue=\"SEX\", kind=\"count\",palette=\"pastel\", edgecolor=\".6\", orient =\"h\", height=8.27, aspect=11.7/8.27)\n",
    "    sns.displot(dataset_for_analyses, x=col, hue=\"SEX\", kind=\"kde\", fill=True)\n",
    "    plt.title(f\"Value counts for {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['RAC1P', 'MAR', 'SCHL', 'CIT', 'COW', 'PINCP']:\n",
    "    sns.catplot(data=dataset_for_analyses, y=col, hue=\"SEX\", kind=\"count\",palette=\"pastel\", edgecolor=\".6\", orient =\"h\", height=8.27, aspect=11.7/8.27)\n",
    "    plt.title(f\"Value counts for {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for RAC1P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['AGEP', 'WKHP', 'PWGTP']:\n",
    "    sns.displot(dataset_for_analyses, x=col, hue=\"RAC1P\", kind=\"kde\", fill=True)\n",
    "    plt.title(f\"Value counts for {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['SEX', 'MAR', 'SCHL', 'CIT', 'COW', 'PINCP']:\n",
    "    sns.catplot(data=dataset_for_analyses, y=col, hue=\"RAC1P\", kind=\"count\",palette=\"pastel\", edgecolor=\".6\", orient =\"h\", height=8.27, aspect=11.7/8.27)\n",
    "    plt.title(f\"Value counts for {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Look at the correlations between SEX and other variables.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. When discussing correlations, do not forget to use the correct metric (e.g. continuous-categorical\n",
    "features etc.). You can use dython.nominal.associations and seaborn.heatmap.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CramerV for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label = preprocessing.LabelEncoder()\n",
    "label_encoded = pd.DataFrame() \n",
    "\n",
    "for i in dataset_for_analyses[['RAC1P', 'SEX', 'SCHL', 'CIT', 'COW', 'PINCP']]:\n",
    "  label_encoded[i]=label.fit_transform(dataset_for_analyses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "def cramers_V(var1,var2) :\n",
    "  crosstab =np.array(pd.crosstab(var1,var2, rownames=None, colnames=None)) # Cross table building\n",
    "  stat = chi2_contingency(crosstab)[0] # Keeping of the test statistic of the Chi2 test\n",
    "  obs = np.sum(crosstab) # Number of observations\n",
    "  mini = min(crosstab.shape)-1 # Take the minimum value between the columns and the rows of the cross table\n",
    "  return (stat/(obs*mini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows= []\n",
    "\n",
    "for var1 in label_encoded:\n",
    "  col = []\n",
    "  for var2 in label_encoded :\n",
    "    cramers =cramers_V(label_encoded[var1], label_encoded[var2]) # Cramer's V test\n",
    "    col.append(round(cramers,2)) # Keeping of the rounded value of the Cramer's V  \n",
    "  rows.append(col)\n",
    "  \n",
    "cramers_results = np.array(rows)\n",
    "cr = pd.DataFrame(cramers_results, columns = label_encoded.columns, index =label_encoded.columns)\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask = np.zeros_like(cr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "  ax = sns.heatmap(cr)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point-biserial correlation coefficient for categorical variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "point_label_encoded = pd.DataFrame() \n",
    "point = dataset_for_analyses[['SEX', 'AGEP','WKHP', 'PWGTP']]\n",
    "point\n",
    "for i in point.columns:\n",
    "  point_label_encoded[i]=label.fit_transform(dataset_for_analyses[i])\n",
    "print(stats.pointbiserialr(point_label_encoded['AGEP'], point_label_encoded['SEX']))\n",
    "print(stats.pointbiserialr(point_label_encoded['WKHP'], point_label_encoded['SEX']))\n",
    "print(stats.pointbiserialr(point_label_encoded['WKHP'], point_label_encoded['PWGTP']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for RAC1P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "point_label_encoded2 = pd.DataFrame() \n",
    "point = dataset_for_analyses[['RAC1P', 'AGEP','WKHP', 'PWGTP']]\n",
    "point\n",
    "for i in point.columns:\n",
    "  point_label_encoded2[i]=label.fit_transform(dataset_for_analyses[i])\n",
    "print(stats.pointbiserialr(point_label_encoded2['AGEP'], point_label_encoded2['RAC1P']))\n",
    "print(stats.pointbiserialr(point_label_encoded2['WKHP'], point_label_encoded2['RAC1P']))\n",
    "print(stats.pointbiserialr(point_label_encoded2['PWGTP'], point_label_encoded2['RAC1P']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Cover the following aspect: Proxies (refer to Lecture 5 Slide #56: How to handle bias?**\n",
    "\n",
    "A proxy mechanism refers to a method or criterion that is used to indirectly measure or predict something else. In the context of discrimination, a proxy mechanism can result in systematically disadvantaging protected classes if it is used to make decisions or evaluations that disproportionately impact members of those classes.\n",
    "\n",
    "For example, consider a hiring process that uses education level as a proxy for job performance. If members of a protected class have historically had less access to quality education due to discrimination or other factors, then using education level as a hiring criterion could disadvantage those individuals and perpetuate the effects of discrimination.\n",
    "\n",
    "Another example is the use of credit scores as a proxy for financial responsibility in lending. If members of a protected class are more likely to have lower credit scores due to systemic discrimination or socioeconomic factors, then using credit scores as a lending criterion could result in those individuals being denied loans or being offered less favorable terms.\n",
    "\n",
    "In both of these examples, the proxy mechanism is not inherently discriminatory, but its use can lead to discrimination by systematically disadvantaging members of protected classes. To address this issue, it may be necessary to examine the underlying causes of the disparities and develop alternative evaluation criteria that do not rely on proxies that perpetuate discrimination."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Supplement your answer with several visualisations. e.g. distributions of variables per protected\n",
    "group (you do not have to provide all of them, but the ones you find interesting).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(dataset_for_analyses)\n",
    "g.map_upper(sns.histplot)\n",
    "g.map_lower(sns.kdeplot, fill=True)\n",
    "g.map_diag(sns.histplot, kde=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Model & Data Debiasing\n",
    "Now we are going to train a model to predict the income of a person based on the attributes we have\n",
    "at hand. We want to have a model with the high predictive performance, but we also want to make\n",
    "sure that our model does not discriminate against any protected groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1.: Data\n",
    "1. Convert categorical to one-hot encoding.\n",
    "2. Remove redundant categorical columns (as you have done in Lecture 6).\n",
    "3. Remove protected attributes from the data (keep it aside).\n",
    "4. Split data into Training and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>COW_Employee of a private for-profit company or business, or of an individual, for wages, salary, or commissions</th>\n",
       "      <th>COW_Employee of a private not-for-profit, tax-exempt, or charitable organization</th>\n",
       "      <th>COW_Federal government employee</th>\n",
       "      <th>COW_Local government employee (city, county, etc.)</th>\n",
       "      <th>COW_Self-employed in own incorporated business, professional practice or farm</th>\n",
       "      <th>COW_Self-employed in own not incorporated business, professional practice, or farm</th>\n",
       "      <th>COW_State government employee</th>\n",
       "      <th>...</th>\n",
       "      <th>RELP_Parent-in-law</th>\n",
       "      <th>RELP_Reference person</th>\n",
       "      <th>RELP_Roomer or boarder</th>\n",
       "      <th>RELP_Son-in-law or daughter-in-law</th>\n",
       "      <th>RELP_Stepson or stepdaughter</th>\n",
       "      <th>RELP_Unmarried partner</th>\n",
       "      <th>SEX_Female</th>\n",
       "      <th>SEX_Male</th>\n",
       "      <th>RAC1P_Black or African American alone</th>\n",
       "      <th>RAC1P_White alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  WKHP  PWGTP  \\\n",
       "0  21.0  20.0   52.0   \n",
       "1  65.0   8.0   33.0   \n",
       "2  33.0  40.0   53.0   \n",
       "3  18.0  18.0  106.0   \n",
       "4  27.0  50.0   23.0   \n",
       "\n",
       "   COW_Employee of a private for-profit company or business, or of an individual, for wages, salary, or commissions  \\\n",
       "0                                                0.0                                                                  \n",
       "1                                                0.0                                                                  \n",
       "2                                                1.0                                                                  \n",
       "3                                                0.0                                                                  \n",
       "4                                                0.0                                                                  \n",
       "\n",
       "   COW_Employee of a private not-for-profit, tax-exempt, or charitable organization  \\\n",
       "0                                                0.0                                  \n",
       "1                                                1.0                                  \n",
       "2                                                0.0                                  \n",
       "3                                                1.0                                  \n",
       "4                                                0.0                                  \n",
       "\n",
       "   COW_Federal government employee  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              1.0   \n",
       "\n",
       "   COW_Local government employee (city, county, etc.)  \\\n",
       "0                                                0.0    \n",
       "1                                                0.0    \n",
       "2                                                0.0    \n",
       "3                                                0.0    \n",
       "4                                                0.0    \n",
       "\n",
       "   COW_Self-employed in own incorporated business, professional practice or farm  \\\n",
       "0                                                0.0                               \n",
       "1                                                0.0                               \n",
       "2                                                0.0                               \n",
       "3                                                0.0                               \n",
       "4                                                0.0                               \n",
       "\n",
       "   COW_Self-employed in own not incorporated business, professional practice, or farm  \\\n",
       "0                                                0.0                                    \n",
       "1                                                0.0                                    \n",
       "2                                                0.0                                    \n",
       "3                                                0.0                                    \n",
       "4                                                0.0                                    \n",
       "\n",
       "   COW_State government employee  ...  RELP_Parent-in-law  \\\n",
       "0                            1.0  ...                 0.0   \n",
       "1                            0.0  ...                 0.0   \n",
       "2                            0.0  ...                 0.0   \n",
       "3                            0.0  ...                 0.0   \n",
       "4                            0.0  ...                 0.0   \n",
       "\n",
       "   RELP_Reference person  RELP_Roomer or boarder  \\\n",
       "0                    0.0                     0.0   \n",
       "1                    0.0                     0.0   \n",
       "2                    0.0                     0.0   \n",
       "3                    0.0                     0.0   \n",
       "4                    0.0                     0.0   \n",
       "\n",
       "   RELP_Son-in-law or daughter-in-law  RELP_Stepson or stepdaughter  \\\n",
       "0                                 0.0                           0.0   \n",
       "1                                 0.0                           0.0   \n",
       "2                                 0.0                           0.0   \n",
       "3                                 0.0                           0.0   \n",
       "4                                 0.0                           0.0   \n",
       "\n",
       "   RELP_Unmarried partner  SEX_Female  SEX_Male  \\\n",
       "0                     0.0         0.0       1.0   \n",
       "1                     0.0         0.0       1.0   \n",
       "2                     0.0         0.0       1.0   \n",
       "3                     0.0         1.0       0.0   \n",
       "4                     0.0         0.0       1.0   \n",
       "\n",
       "   RAC1P_Black or African American alone  RAC1P_White alone  \n",
       "0                                    0.0                1.0  \n",
       "1                                    0.0                1.0  \n",
       "2                                    0.0                1.0  \n",
       "3                                    0.0                1.0  \n",
       "4                                    0.0                1.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(\n",
    "    features=ACSIncomeNew.features, definition_df=definition_df)\n",
    "\n",
    "# 1- Convert categroical to one-hot encoding\n",
    "features, labels, groups = ACSIncomeNew.df_to_pandas(\n",
    "    acs_data, categories=categories, dummies=True)\n",
    "# groups now contain information about SEX and RAC1P\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the protected features:\n",
      "Column ID: 57 (SEX_Female)\n",
      "Column ID: 58 (RAC1P_Black or African American alone)\n"
     ]
    }
   ],
   "source": [
    "# 2 - Drop the \"redundant\" columns\n",
    "features = features.drop([\"RELP_Unmarried partner\",\n",
    "                          \"CIT_U.S. citizen by naturalization\",\n",
    "                          \"SEX_Male\",\n",
    "                          \"SCHL_1 or more years of college credit, no degree\",\n",
    "                          \"MAR_Divorced\",\n",
    "                          \"RELP_Adopted son or daughter\",\n",
    "                          'COW_Working without pay in family business or farm',\n",
    "                          \"RAC1P_White alone\"], axis=1)\n",
    "\n",
    "print(\"Columns with the protected features:\")\n",
    "for i, f in enumerate(features.columns):\n",
    "    if (\"RAC1P\" in f) or (\"SEX\" in f):\n",
    "        print(\"Column ID: %s\" % i, \"(%s)\" % f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Drop protected features from features\n",
    "protected = [\n",
    "    \"SEX_Female\",\n",
    "    \"RAC1P_Black or African American alone\"\n",
    "]\n",
    "if protected[0] in features.columns.to_list() or protected[1] in features.columns.to_list():\n",
    "    features = features.drop(protected, axis=1)\n",
    "else:\n",
    "    print(\"No protected features present already\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numeric features in a different dataframe (used for PCA)\n",
    "def scale_columns(data, columns=[\"AGEP\", \"WKHP\", \"PWGTP\"], scaler=MinMaxScaler()):\n",
    "\n",
    "    for column in columns:\n",
    "        data[column] = scaler.fit_transform(\n",
    "            np.array(data[column]).reshape(-1, 1))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "features_normalized = features.copy()\n",
    "features_normalized = scale_columns(features_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>COW_Employee of a private for-profit company or business, or of an individual, for wages, salary, or commissions</th>\n",
       "      <th>COW_Employee of a private not-for-profit, tax-exempt, or charitable organization</th>\n",
       "      <th>COW_Federal government employee</th>\n",
       "      <th>COW_Local government employee (city, county, etc.)</th>\n",
       "      <th>COW_Self-employed in own incorporated business, professional practice or farm</th>\n",
       "      <th>COW_Self-employed in own not incorporated business, professional practice, or farm</th>\n",
       "      <th>COW_State government employee</th>\n",
       "      <th>...</th>\n",
       "      <th>RELP_Husband/wife</th>\n",
       "      <th>RELP_Institutionalized group quarters population</th>\n",
       "      <th>RELP_Noninstitutionalized group quarters population</th>\n",
       "      <th>RELP_Other nonrelative</th>\n",
       "      <th>RELP_Other relative</th>\n",
       "      <th>RELP_Parent-in-law</th>\n",
       "      <th>RELP_Reference person</th>\n",
       "      <th>RELP_Roomer or boarder</th>\n",
       "      <th>RELP_Son-in-law or daughter-in-law</th>\n",
       "      <th>RELP_Stepson or stepdaughter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.036299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.037011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.074733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.015658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGEP      WKHP     PWGTP  \\\n",
       "0  0.051948  0.193878  0.036299   \n",
       "1  0.623377  0.071429  0.022776   \n",
       "2  0.207792  0.397959  0.037011   \n",
       "3  0.012987  0.173469  0.074733   \n",
       "4  0.129870  0.500000  0.015658   \n",
       "\n",
       "   COW_Employee of a private for-profit company or business, or of an individual, for wages, salary, or commissions  \\\n",
       "0                                                0.0                                                                  \n",
       "1                                                0.0                                                                  \n",
       "2                                                1.0                                                                  \n",
       "3                                                0.0                                                                  \n",
       "4                                                0.0                                                                  \n",
       "\n",
       "   COW_Employee of a private not-for-profit, tax-exempt, or charitable organization  \\\n",
       "0                                                0.0                                  \n",
       "1                                                1.0                                  \n",
       "2                                                0.0                                  \n",
       "3                                                1.0                                  \n",
       "4                                                0.0                                  \n",
       "\n",
       "   COW_Federal government employee  \\\n",
       "0                              0.0   \n",
       "1                              0.0   \n",
       "2                              0.0   \n",
       "3                              0.0   \n",
       "4                              1.0   \n",
       "\n",
       "   COW_Local government employee (city, county, etc.)  \\\n",
       "0                                                0.0    \n",
       "1                                                0.0    \n",
       "2                                                0.0    \n",
       "3                                                0.0    \n",
       "4                                                0.0    \n",
       "\n",
       "   COW_Self-employed in own incorporated business, professional practice or farm  \\\n",
       "0                                                0.0                               \n",
       "1                                                0.0                               \n",
       "2                                                0.0                               \n",
       "3                                                0.0                               \n",
       "4                                                0.0                               \n",
       "\n",
       "   COW_Self-employed in own not incorporated business, professional practice, or farm  \\\n",
       "0                                                0.0                                    \n",
       "1                                                0.0                                    \n",
       "2                                                0.0                                    \n",
       "3                                                0.0                                    \n",
       "4                                                0.0                                    \n",
       "\n",
       "   COW_State government employee  ...  RELP_Husband/wife  \\\n",
       "0                            1.0  ...                0.0   \n",
       "1                            0.0  ...                0.0   \n",
       "2                            0.0  ...                0.0   \n",
       "3                            0.0  ...                0.0   \n",
       "4                            0.0  ...                0.0   \n",
       "\n",
       "   RELP_Institutionalized group quarters population  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               1.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   RELP_Noninstitutionalized group quarters population  \\\n",
       "0                                                1.0     \n",
       "1                                                1.0     \n",
       "2                                                0.0     \n",
       "3                                                1.0     \n",
       "4                                                1.0     \n",
       "\n",
       "   RELP_Other nonrelative  RELP_Other relative  RELP_Parent-in-law  \\\n",
       "0                     0.0                  0.0                 0.0   \n",
       "1                     0.0                  0.0                 0.0   \n",
       "2                     0.0                  0.0                 0.0   \n",
       "3                     0.0                  0.0                 0.0   \n",
       "4                     0.0                  0.0                 0.0   \n",
       "\n",
       "   RELP_Reference person  RELP_Roomer or boarder  \\\n",
       "0                    0.0                     0.0   \n",
       "1                    0.0                     0.0   \n",
       "2                    0.0                     0.0   \n",
       "3                    0.0                     0.0   \n",
       "4                    0.0                     0.0   \n",
       "\n",
       "   RELP_Son-in-law or daughter-in-law  RELP_Stepson or stepdaughter  \n",
       "0                                 0.0                           0.0  \n",
       "1                                 0.0                           0.0  \n",
       "2                                 0.0                           0.0  \n",
       "3                                 0.0                           0.0  \n",
       "4                                 0.0                           0.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_normalized.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- . Split data into Training and Test sets (used for PCA)\n",
    "def split_dataset(features, labels, groups, N=20000):\n",
    "\n",
    "    X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "        features.values, labels.values.reshape(-1), groups, test_size=0.3, random_state=0, shuffle=True)\n",
    "\n",
    "    N = 20000  # Subsampling due to speed\n",
    "\n",
    "    X_train = X_train[:N]\n",
    "    y_train = y_train[:N]\n",
    "    group_train = group_train[:N]\n",
    "    X_test = X_test[:N]\n",
    "    y_test = y_test[:N]\n",
    "    group_test = group_test[:N]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, group_train, group_test\n",
    "\n",
    "\n",
    "# Split already normalized dataset\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = split_dataset(\n",
    "    features_normalized, labels, groups, N=20000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2 - Baseline Model\n",
    "Use the following arguments in the `opt.fmin_funct`: `xtol=1e-4, ftol=1e-4,  maxfun=1000`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part1: Build your own implementation of the Logistic Regression with L2-penalty (aka Ridge Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions for custom implementation\n",
    "\n",
    "def sigmoid(beta_x, eps=1e-10):\n",
    "    \"\"\"\n",
    "    This is logistic regression\n",
    "    f = 1/(1+exp(-beta^T * x))  \n",
    "    This function assumes as input that you have already multiplied beta and X together\n",
    "    \"\"\"\n",
    "    return 1/(1 + np.exp(-beta_x + eps))\n",
    "\n",
    "\n",
    "def logistic_loss(y_true, y_pred, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Loss for the logistic regression, y_preds are probabilities\n",
    "    eps: epsilon for stability\n",
    "    \"\"\"\n",
    "    summand_1 = y_true * np.log(y_pred + eps)\n",
    "    summand_2 = (1-y_true) * np.log(1 - y_pred + eps)\n",
    "\n",
    "    return -np.mean(summand_1 + summand_2)\n",
    "\n",
    "\n",
    "def l2_loss(beta):\n",
    "    \"\"\"\n",
    "    L2-Regularisation\n",
    "    \"\"\"\n",
    "    return sum(beta**2)\n",
    "\n",
    "\n",
    "def fair_loss(y, y_pred, groups):\n",
    "    \"\"\"\n",
    "    Group fairness Loss\n",
    "\n",
    "    y_pred: sigmoid(βTx)\n",
    "    y: prediction in 0 or 1\n",
    "    groups: dataframe with column for each protected variable\n",
    "    \"\"\"\n",
    "\n",
    "    cum_result = 0\n",
    "\n",
    "    # compute once per protected variable\n",
    "    for p_group in groups.columns.to_list():\n",
    "\n",
    "        group = groups[p_group].to_numpy()\n",
    "        \n",
    "\n",
    "        y_g1 = y[group == 1]\n",
    "        y_pred_g1 = y_pred[group == 1]\n",
    "        y_g2 = y[group == 2]\n",
    "        y_pred_g2 = y_pred[group == 2]\n",
    "\n",
    "        n1 = np.sum(group == 1)\n",
    "        n2 = np.sum(group == 2)\n",
    "\n",
    "        # INDIVIDUAL CONSTRAINT\n",
    "        \n",
    "        # all pairwise equalities between y_g1 and y_g2\n",
    "        distance = np.equal.outer(y_g1, y_g2).astype(int)\n",
    "        # all pairwise differences between y_pred_g1 and y_pred_g2\n",
    "        diff = np.subtract.outer(y_pred_g1, y_pred_g2)      \n",
    "        diff_squared = (diff)**2  # square the differenes\n",
    "        cost = np.sum(distance * diff_squared)  # multiply both\n",
    "        result = (cost/(n1*n2))  # result for this protected variable\n",
    "        \n",
    "        cum_result += result  # combined result for all proetected variables\n",
    "        \n",
    "        # print(f'los for {p_group}: {result}')\n",
    "\n",
    "    return cum_result\n",
    "\n",
    "\n",
    "def compute_gradient_withl2(beta, X, y, groups, _lambda, _gamma):\n",
    "    \"\"\"Calculate the gradient - used for finding the best beta values. \n",
    "       You do not need to use groups and lambda (fmin_tnc expects same input as \n",
    "       in func, that's why they are included here)\n",
    "\n",
    "       Note: we do not include fairness constrint here\n",
    "       \"\"\"\n",
    "\n",
    "    grad = np.zeros(beta.shape)\n",
    "    y_pred = sigmoid(X.dot(beta))\n",
    "    diff = y_pred - y\n",
    "    m = beta.shape\n",
    "\n",
    "    # Loop over features and correponding weights and calcualte gradient for each\n",
    "    for j in range(len(grad)):\n",
    "        if j == 0:\n",
    "            # we do not want to regularize the intercept\n",
    "            grad[j] = np.dot(diff, X[:, j])/m\n",
    "        else:\n",
    "            grad[j] = np.dot(diff, X[:, j])/m + 2*beta[j]*_gamma\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def compute_cost_withl2(beta, X, y, groups, _lambda, _gamma):\n",
    "    \"\"\"Computes cost function with constraints\"\"\"\n",
    "\n",
    "    # Logistic function prediction and real value, all in numeric\n",
    "    y_pred = sigmoid(X.dot(beta))\n",
    "    y_real = np.array(y).astype(int)\n",
    "\n",
    "    # Calculate each loss and add up\n",
    "    loss_log = logistic_loss(y_real, y_pred, eps=1e-10)\n",
    "    loss_l2 = _gamma * l2_loss(beta[1:])  # l2 loss does not consider intercept\n",
    "\n",
    "    loss = loss_log + \\\n",
    "        loss_l2\n",
    "    # print('log',round(loss_log, 4), 'l2', round(loss_l2,4), 'TOTAL:', round(loss,4))\n",
    "\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_cost_withl2_withfairness(beta, X, y, groups, _lambda, _gamma):\n",
    "    \"\"\"Computes cost function with constraints\"\"\"\n",
    "\n",
    "    # Logistic function prediction and real value, all in numeric\n",
    "    y_pred = sigmoid(X.dot(beta))\n",
    "    y_real = np.array(y).astype(int)\n",
    "\n",
    "    # Calculate each loss and add up\n",
    "    loss_log = logistic_loss(y_real, y_pred, eps=1e-10)\n",
    "    loss_fair = _lambda * fair_loss(y_real, y_pred, groups)\n",
    "    loss_l2 = _gamma * l2_loss(beta[1:])  # l2 loss does not consider intercept\n",
    "\n",
    "    loss =  loss_log + \\\n",
    "        loss_l2 + \\\n",
    "            loss_fair\n",
    "\n",
    "    print('log',round(loss_log, 4),'fair', round(loss_fair,7),'l2', round(loss_l2,4), 'TOTAL:', round(loss,4))\n",
    "    # print('log',round(loss_log, 4), 'l2', round(loss_l2,4), 'TOTAL:', round(loss,4))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def fit_logistic_l2(X, y, groups, lambda_used, gamma_used, include_fairness=False, aprox_grad=False):\n",
    "    '''\n",
    "    Function that finds optimal weights for given input\n",
    "\n",
    "    X: numpy array with features\n",
    "    y: numpy array with labels\n",
    "    groups: pandas dataframe with protected groups\n",
    "\n",
    "    '''\n",
    "\n",
    "    betas = np.random.rand(X.shape[1])\n",
    "\n",
    "    if include_fairness:\n",
    "        cost_func = compute_cost_withl2_withfairness\n",
    "    else:\n",
    "        cost_func = compute_cost_withl2\n",
    "        \n",
    "    if aprox_grad:\n",
    "        new_weights, q, code = opt.fmin_tnc(func=cost_func, x0=betas, messages=0,  xtol=1e-3, ftol=1e-3, approx_grad=True, maxfun=1000,\n",
    "                                            args=(X, y, groups, lambda_used, gamma_used))\n",
    "    else:\n",
    "        new_weights, q, code = opt.fmin_tnc(func=cost_func, x0=betas, messages=0,  fprime=compute_gradient_withl2, \n",
    "                                            args=(X, y, groups, lambda_used, gamma_used), xtol=1e-4, ftol=1e-4,  maxfun=1000)\n",
    "    return new_weights, q, code \n",
    "\n",
    "\n",
    "def perform_crossvalidation(X, y, groups, lambda_values, gamma_values, n_folds=5, include_fairness=False):\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    all_validation_scores = []\n",
    "    l, g = np.meshgrid(lambda_values, gamma_values)\n",
    "    all_combinations = np.column_stack((l.ravel(), g.ravel()))\n",
    "\n",
    "    # Calculate score for each possible value and store\n",
    "    for combination in all_combinations: \n",
    "        fair_penalty = combination[0]\n",
    "        l2_penalty = combination[1]\n",
    "        print(f\"Lambda: {fair_penalty}, Gamma: {l2_penalty}\")\n",
    "        \n",
    "        crossvalidation_scores = [] # here we save result for each crossvalidation run\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            # split the data into training and validation sets\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            groups_train, groups_val = groups.iloc[train_idx], groups.iloc[val_idx]\n",
    "\n",
    "            # normalize the data using the training set and apply the same transformation to the validation set\n",
    "            scaler.fit(X_train)\n",
    "            X_train_norm = scaler.transform(X_train)\n",
    "            X_val_norm = scaler.transform(X_val)\n",
    "\n",
    "            # Fit custom model\n",
    "            weights, _, _ = fit_logistic_l2(X_train_norm, y_train, groups_train,\n",
    "                                    lambda_used = fair_penalty, gamma_used = l2_penalty, include_fairness=include_fairness)\n",
    "            prob = sigmoid(X_val_norm.dot(weights))\n",
    "            y_pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "            score = np.mean(y_pred == y_val)\n",
    "\n",
    "            crossvalidation_scores.append(score)\n",
    "            \n",
    "        mean_score = np.mean(crossvalidation_scores)\n",
    "        print(f\"---> mean score: {round(mean_score, 4)}\")\n",
    "\n",
    "        all_validation_scores.append(mean_score) # we save mean result for each parameter combination\n",
    "\n",
    "    optimal_fair_penalty, optimal_l2_penalty  = all_combinations[np.argmax(all_validation_scores)]\n",
    "    \n",
    "    return optimal_l2_penalty, optimal_fair_penalty, all_validation_scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part2: Use Cross-Validation to find the most optimal value for L2-penalty (you should implement it yourself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.0, Gamma: 1e-05\n",
      "---> mean score: 0.8201\n",
      "Lambda: 0.0, Gamma: 2.1544346900318823e-05\n",
      "---> mean score: 0.8193\n",
      "Lambda: 0.0, Gamma: 4.641588833612782e-05\n",
      "---> mean score: 0.8192\n",
      "Lambda: 0.0, Gamma: 0.0001\n",
      "---> mean score: 0.818\n",
      "Lambda: 0.0, Gamma: 0.00021544346900318823\n",
      "---> mean score: 0.8158\n",
      "Lambda: 0.0, Gamma: 0.00046415888336127773\n",
      "---> mean score: 0.8088\n",
      "Lambda: 0.0, Gamma: 0.001\n",
      "---> mean score: 0.7992\n",
      "Lambda: 0.0, Gamma: 0.002154434690031882\n",
      "---> mean score: 0.7911\n",
      "Lambda: 0.0, Gamma: 0.004641588833612777\n",
      "---> mean score: 0.7799\n",
      "Lambda: 0.0, Gamma: 0.01\n",
      "---> mean score: 0.7707\n"
     ]
    }
   ],
   "source": [
    "# Sample dataframes\n",
    "sampled_rows = features.sample(n=20000, random_state=0).index\n",
    "features_sampled = features.loc[sampled_rows]\n",
    "groups_sampled = groups.loc[sampled_rows]\n",
    "labels_sampled = labels.loc[sampled_rows]\n",
    "\n",
    "# Add column to features for intercept\n",
    "features_sampled = features_sampled.insert(0, 'intercept', 1)\n",
    "\n",
    "# Define search space of gammas (penalty for l2 norm)\n",
    "gammas = np.logspace(-5, -2, num=10, base=1e1) # we search from 1e-5 to 1e-2\n",
    "lambdas = [0] # we don't care about fairness penalty now\n",
    "\n",
    "# 2- Perform crossvalidation and get best lambda\n",
    "optimal_l2_penalty, optimal_fair_penalty, all_validation_scores = perform_crossvalidation(\n",
    "    features.values, labels.values.reshape(-1), groups, gamma_values = gammas, lambda_values=lambdas, n_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda found using cross-validation: 1e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Optimal lambda found using cross-validation: {optimal_l2_penalty}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Evaluate the overall performance of the final model on the Test Set (use an appropriate metrics) + report uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary funcitons for plotting and evlauating \n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate uncertainty\n",
    "    num_samples = len(y_test)\n",
    "    num_bootstraps = 1000\n",
    "    bootstrap_indices = np.random.randint(0, num_samples, (num_bootstraps, num_samples))\n",
    "    bootstrap_scores = np.zeros((num_bootstraps, 4))\n",
    "    \n",
    "    for i in range(num_bootstraps):\n",
    "        y_test_bootstrap = y_test[bootstrap_indices[i]]\n",
    "        y_pred_bootstrap = y_pred[bootstrap_indices[i]]\n",
    "        bootstrap_scores[i, 0] = accuracy_score(y_test_bootstrap, y_pred_bootstrap)\n",
    "        bootstrap_scores[i, 1] = precision_score(y_test_bootstrap, y_pred_bootstrap)\n",
    "        bootstrap_scores[i, 2] = recall_score(y_test_bootstrap, y_pred_bootstrap)\n",
    "        bootstrap_scores[i, 3] = f1_score(y_test_bootstrap, y_pred_bootstrap)\n",
    "    \n",
    "    # std for confidence intervals\n",
    "    accuracy_std = np.std(bootstrap_scores[:, 0])\n",
    "    precision_std = np.std(bootstrap_scores[:, 1])\n",
    "    recall_std = np.std(bootstrap_scores[:, 2])\n",
    "    f1_std = np.std(bootstrap_scores[:, 3])\n",
    "    \n",
    "    # Return metrics and uncertainty in dictionary\n",
    "    return {'accuracy': [accuracy,accuracy_std], 'precision': [precision,precision_std], 'recall': [recall, recall_std], 'f1': [f1, f1_std]}\n",
    "        \n",
    "def plot_metrics(metrics, ax, fig, savefig=False, plotfig=True, label=None, title='Model Performance', filename=None):\n",
    "    \n",
    "    # extract metrics and uncertainties\n",
    "    metric_names = list(metrics.keys())\n",
    "    metric_values = [m[0] for m in metrics.values()]\n",
    "    metric_uncertainties = [m[1] for m in metrics.values()]\n",
    "\n",
    "    # create bar plot with error bars\n",
    "    ax.errorbar(metric_names, metric_values, yerr=metric_uncertainties,label=label, \\\n",
    "                    fmt='o',capsize=4, alpha=0.7, markersize=3)\n",
    "\n",
    "\n",
    "    # add title and labels\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Metric')\n",
    "    ax.set_ylabel('Value')\n",
    "\n",
    "    # set y-axis limits\n",
    "    ax.set_ylim([0.5, 1])\n",
    "\n",
    "    # add grid lines\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    if plotfig:\n",
    "        plt.show()\n",
    "    \n",
    "    if savefig:\n",
    "        outpath = os.path.join(os.getcwd(), \"plots\", \"task2\")\n",
    "        if not os.path.exists(outpath):\n",
    "            os.mkdir(outpath)\n",
    "        fig.savefig(os.path.join(outpath, filename), dpi=200, bbox_inches='tight' )\n",
    "        \n",
    "    return ax\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to our data and obtain prediction\n",
    "weights, q, code  = fit_logistic_l2(np.insert(X_train, 0, 1, axis=1), y_train, groups=None,\n",
    "                            gamma_used=optimal_l2_penalty,lambda_used=optimal_fair_penalty, include_fairness=False)\n",
    "prob = sigmoid(np.insert(X_test, 0, 1, axis=1).dot(weights))\n",
    "y_pred = (prob >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = evaluate_model(y_pred=y_pred, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot metrics\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax = plot_metrics(evaluation_results, ax,fig, savefig=True, filename=\"Task2.2_part3_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Model Performance'}, xlabel='Metric', ylabel='Value'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot metrics\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plot_metrics(evaluation_results, ax,fig, savefig=True, filename=\"Task2.2_part3_plot.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - Look at the fairness metric associated with each SEX and RAC1P group. Are there any discrepancies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX\n",
      "RAC1P\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate performance plot split by protected features' values\n",
    "fig, axes = plt.subplots(1,2, figsize=(16,6))\n",
    "\n",
    "for i, group_name in enumerate(groups.columns.to_list()):\n",
    "    \n",
    "    print(group_name)\n",
    "    vals = groups[group_name].unique().tolist()\n",
    "    \n",
    "    for val in vals:\n",
    "        \n",
    "        # Only test set changes, same weights used all the time\n",
    "        X_test_temp = X_test[group_test[group_name] == val]\n",
    "        y_test_temp  = y_test[group_test[group_name] == val]\n",
    "\n",
    "        prob_temp = sigmoid(np.insert(X_test_temp, 0, 1, axis=1).dot(weights))\n",
    "        y_pred_temp = (prob_temp >= 0.5).astype(int)\n",
    "\n",
    "        evaluation_results_temp = evaluate_model( y_test_temp,y_pred_temp)\n",
    "\n",
    "        axes[i] = plot_metrics(evaluation_results_temp, axes[i], fig, label=val, plotfig=False, savefig=False, title=f'Model performance by {group_name}')\n",
    "    \n",
    "    axes[i].legend()\n",
    "\n",
    "outpath = os.path.join(os.getcwd(), \"plots\", \"task2\")\n",
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)\n",
    "fig.savefig(os.path.join(outpath, \"Task2.2_part4_plot.png\"), dpi=200, bbox_inches='tight' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3\n",
    "Use the following arguments in the `opt.fmin_funct`: ` xtol=1e-3, ftol=1e-3, approx_grad=True, maxfun=1000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split already normalized into even smaller pieces, since this part is very expensive computationally\n",
    "X_train_small, X_test_small, y_train_small, y_test_small, group_train_small, group_test_small = split_dataset(\n",
    "    features_normalized, labels, groups, N=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Add Individual Fairness Penalty to your baseline model (refer to Lecture 5 Exercises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Plot Pareto Curve by varying λ = [1e − 3, 5e − 3, 1e − 2, 5e − 2, 0.1, 1], evaluate the performance of the model (using your favourite metric). Plot a curve for each group of protected attributes (i.e. 4 curves). What happens as we increase the penalty? Is there a point where all groups get similar performance metric values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the values of λ to use\n",
    "lambdas = [1e-3, 5e-3, 1e-2, 5e-2, 0.1, 1]\n",
    "\n",
    "# create lists to store the results for each lambda and each metric\n",
    "accuracy_protected = []\n",
    "accuracy_unprotected = []\n",
    "precision_protected = []\n",
    "precision_unprotected = []\n",
    "recall_protected = []\n",
    "recall_unprotected = []\n",
    "f1_protected = []\n",
    "f1_unprotected = []\n",
    "\n",
    "# loop over the lambdas and train the model for each one\n",
    "for l in lambdas:\n",
    "    # train the model on the protected group\n",
    "    X_protected = protected_group[['feature1', 'feature2', 'feature3']].values\n",
    "    y_protected = protected_group['label'].values\n",
    "    model_protected = LogisticRegression(penalty='l1', C=1/l, solver='liblinear')\n",
    "    model_protected.fit(X_protected, y_protected)\n",
    "    \n",
    "    # evaluate the model on the protected group\n",
    "    y_pred_protected = model_protected.predict(X_protected)\n",
    "    accuracy_protected.append(accuracy_score(y_protected, y_pred_protected))\n",
    "    precision_protected.append(precision_score(y_protected, y_pred_protected))\n",
    "    recall_protected.append(recall_score(y_protected, y_pred_protected))\n",
    "    f1_protected.append(f1_score(y_protected, y_pred_protected))\n",
    "    \n",
    "    # train the model on the unprotected group\n",
    "    X_unprotected = unprotected_group[['feature1', 'feature2', 'feature3']].values\n",
    "    y_unprotected = unprotected_group['label'].values\n",
    "    model_unprotected = LogisticRegression(penalty='l1', C=1/l, solver='liblinear')\n",
    "    model_unprotected.fit(X_unprotected, y_unprotected)\n",
    "    \n",
    "    # evaluate the model on the unprotected group\n",
    "    y_pred_unprotected = model_unprotected.predict(X_unprotected)\n",
    "    accuracy_unprotected.append(accuracy_score(y_unprotected, y_pred_unprotected))\n",
    "    precision_unprotected.append(precision_score(y_unprotected, y_pred_unprotected))\n",
    "    recall_unprotected.append(recall_score(y_unprotected, y_pred_unprotected))\n",
    "    f1_unprotected.append(f1_score(y_unprotected, y_pred_unprotected))\n",
    "\n",
    "# plot the Pareto curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(accuracy_protected, precision_protected, label='Protected Group')\n",
    "plt.plot(accuracy_unprotected, precision_unprotected, label='Unprotected Group')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Pareto Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Set λ = 0.1 and evaluate the overall performance of the final model on the Test Set (report uncertainty). Use the same metric as you used in Task 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.9868 fair 0.0001312 l2 0.0002 TOTAL: 0.9872\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n",
      "log 0.6236 fair 0.0017302 l2 0.0002 TOTAL: 0.6255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weights_fair, q_fair, code_fair   \u001b[39m=\u001b[39m fit_logistic_l2(np\u001b[39m.\u001b[39;49minsert(X_train_small, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), y_train_small, groups\u001b[39m=\u001b[39;49mgroup_train_small,\n\u001b[1;32m      2\u001b[0m                             gamma_used\u001b[39m=\u001b[39;49moptimal_l2_penalty,lambda_used\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, include_fairness\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, aprox_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[73], line 155\u001b[0m, in \u001b[0;36mfit_logistic_l2\u001b[0;34m(X, y, groups, lambda_used, gamma_used, include_fairness, aprox_grad)\u001b[0m\n\u001b[1;32m    152\u001b[0m     cost_func \u001b[39m=\u001b[39m compute_cost_withl2\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m aprox_grad:\n\u001b[0;32m--> 155\u001b[0m     new_weights, q, code \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49mfmin_tnc(func\u001b[39m=\u001b[39;49mcost_func, x0\u001b[39m=\u001b[39;49mbetas, messages\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,  xtol\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m, ftol\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m, approx_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, maxfun\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m    156\u001b[0m                                         args\u001b[39m=\u001b[39;49m(X, y, groups, lambda_used, gamma_used))\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     new_weights, q, code \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mfmin_tnc(func\u001b[39m=\u001b[39mcost_func, x0\u001b[39m=\u001b[39mbetas, messages\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,  fprime\u001b[39m=\u001b[39mcompute_gradient_withl2, \n\u001b[1;32m    159\u001b[0m                                         args\u001b[39m=\u001b[39m(X, y, groups, lambda_used, gamma_used), xtol\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m, ftol\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m,  maxfun\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_tnc.py:280\u001b[0m, in \u001b[0;36mfmin_tnc\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, epsilon, scale, offset, messages, maxCGit, maxfun, eta, stepmx, accuracy, fmin, ftol, xtol, pgtol, rescale, disp, callback)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# build options\u001b[39;00m\n\u001b[1;32m    264\u001b[0m opts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39meps\u001b[39m\u001b[39m'\u001b[39m: epsilon,\n\u001b[1;32m    265\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m: scale,\n\u001b[1;32m    266\u001b[0m         \u001b[39m'\u001b[39m\u001b[39moffset\u001b[39m\u001b[39m'\u001b[39m: offset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mrescale\u001b[39m\u001b[39m'\u001b[39m: rescale,\n\u001b[1;32m    278\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m}\n\u001b[0;32m--> 280\u001b[0m res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopts)\n\u001b[1;32m    282\u001b[0m \u001b[39mreturn\u001b[39;00m res[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_tnc.py:428\u001b[0m, in \u001b[0;36m_minimize_tnc\u001b[0;34m(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, finite_diff_rel_step, maxfun, **unknown_options)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m         maxfun \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m100\u001b[39m, \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(x0))\n\u001b[0;32m--> 428\u001b[0m rc, nf, nit, x, funv, jacv \u001b[39m=\u001b[39m moduleTNC\u001b[39m.\u001b[39;49mtnc_minimize(\n\u001b[1;32m    429\u001b[0m     func_and_grad, x0, low, up, scale,\n\u001b[1;32m    430\u001b[0m     offset, messages, maxCGit, maxfun,\n\u001b[1;32m    431\u001b[0m     eta, stepmx, accuracy, fmin, ftol,\n\u001b[1;32m    432\u001b[0m     xtol, pgtol, rescale, callback\n\u001b[1;32m    433\u001b[0m )\n\u001b[1;32m    434\u001b[0m \u001b[39m# the TNC documentation states: \"On output, x, f and g may be very\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m# slightly out of sync because of scaling\". Therefore re-evaluate\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m# func_and_grad so they are synced.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m funv, jacv \u001b[39m=\u001b[39m func_and_grad(x)\n",
      "File \u001b[0;32m_moduleTNC.pyx:200\u001b[0m, in \u001b[0;36m_moduleTNC.tnc_minimize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_moduleTNC.pyx:72\u001b[0m, in \u001b[0;36m_moduleTNC.function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[0;32m--> 286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad_impl()\n\u001b[1;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, f0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[1;32m    174\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfinite_diff_options)\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m sparsity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[1;32m    506\u001b[0m                              use_one_sided, method)\n\u001b[1;32m    507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(sparsity) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sparsity) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[39m=\u001b[39m x[i] \u001b[39m-\u001b[39m x0[i]  \u001b[39m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[39m=\u001b[39m fun(x) \u001b[39m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3-point\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(fun(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fun` return value has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mmore than 1 dimension.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[73], line 124\u001b[0m, in \u001b[0;36mcompute_cost_withl2_withfairness\u001b[0;34m(beta, X, y, groups, _lambda, _gamma)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m# Calculate each loss and add up\u001b[39;00m\n\u001b[1;32m    123\u001b[0m loss_log \u001b[39m=\u001b[39m logistic_loss(y_real, y_pred, eps\u001b[39m=\u001b[39m\u001b[39m1e-10\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m loss_fair \u001b[39m=\u001b[39m _lambda \u001b[39m*\u001b[39m fair_loss(y_real, y_pred, groups)\n\u001b[1;32m    125\u001b[0m loss_l2 \u001b[39m=\u001b[39m _gamma \u001b[39m*\u001b[39m l2_loss(beta[\u001b[39m1\u001b[39m:])  \u001b[39m# l2 loss does not consider intercept\u001b[39;00m\n\u001b[1;32m    127\u001b[0m loss \u001b[39m=\u001b[39m  loss_log \u001b[39m+\u001b[39m \\\n\u001b[1;32m    128\u001b[0m     loss_l2 \u001b[39m+\u001b[39m \\\n\u001b[1;32m    129\u001b[0m         loss_fair\n",
      "Cell \u001b[0;32mIn[73], line 62\u001b[0m, in \u001b[0;36mfair_loss\u001b[0;34m(y, y_pred, groups)\u001b[0m\n\u001b[1;32m     60\u001b[0m diff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msubtract\u001b[39m.\u001b[39mouter(y_pred_g1, y_pred_g2)      \n\u001b[1;32m     61\u001b[0m diff_squared \u001b[39m=\u001b[39m (diff)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m  \u001b[39m# square the differenes\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m cost \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(distance \u001b[39m*\u001b[39;49m diff_squared)  \u001b[39m# multiply both\u001b[39;00m\n\u001b[1;32m     63\u001b[0m result \u001b[39m=\u001b[39m (cost\u001b[39m/\u001b[39m(n1\u001b[39m*\u001b[39mn2))  \u001b[39m# result for this protected variable\u001b[39;00m\n\u001b[1;32m     65\u001b[0m cum_result \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m result  \u001b[39m# combined result for all proetected variables\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2296\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2298\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2299\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_fairalgo/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights_fair, q_fair, code_fair   = fit_logistic_l2(np.insert(X_train_small, 0, 1, axis=1), y_train_small, groups=group_train_small,\n",
    "                            gamma_used=optimal_l2_penalty,lambda_used=0.1, include_fairness=True, aprox_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "prob_fair = sigmoid(np.insert(X_test_small, 0, 1, axis=1).dot(weights_fair))\n",
    "y_pred_fair = (prob_fair >= 0.5).astype(int)\n",
    "evaluation_results_fair = evaluate_model( y_test_small, y_pred_fair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Model Performance'}, xlabel='Metric', ylabel='Value'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot metrics\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plot_metrics(evaluation_results_fair, ax,fig, savefig=True, filename=\"Task2.3_part3_plot.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - Set λ = 0.1 and look at the fairness metric associated with each SEX and RAC1P group. What do you see (compare results to the baseline model)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4.: Fair PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protected columns already dropped in features_normalized so no need to substract 4 for PCA column count\n",
    "n_components = len(features_normalized.columns)\n",
    "print(n_components)\n",
    "\n",
    "pca = PCA(n_components=n_components)  # create a PCA object\n",
    "X = pca.fit_transform(features_normalized)  # do the math\n",
    "\n",
    "pca_columns = []\n",
    "for i in range(n_components):\n",
    "    pca_columns.append(f\"PC{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_no_protected = pd.DataFrame(X, columns=pca_columns)\n",
    "pca_no_protected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_merged = pd.concat([pca_no_protected, groups], axis=1)\n",
    "task_1_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "n_features = X_train.shape[1]\n",
    "alpha = 0.05  # significance level\n",
    "# Bonferroni correction for multiple testings\n",
    "corrected_alpha = alpha / (n_features**2/2)\n",
    "\n",
    "##############################\n",
    "# Your code here\n",
    "##############################\n",
    "\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            tmp = df[df[r].notnull() & df[c].notnull()]\n",
    "            pvalues[r][c] = float(round(pearsonr(tmp[r], tmp[c])[1], 4))\n",
    "    return pvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = calculate_pvalues(task_1_merged)\n",
    "p_values = p_values.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_filtered_relevant(df, p_values, corrected_alpha, title):\n",
    "    sns.heatmap(df, annot=False, cmap='rocket', linewidths=0.5,\n",
    "                linecolor='black', mask=p_values > corrected_alpha)\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.tick_params(axis='both', which='both', labelsize=12)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_filtered_relevant(task_1_merged.corr(method='pearson')[\n",
    "                          ['SEX', 'RAC1P']], p_values[['SEX', 'RAC1P']], corrected_alpha, 'Pearson Correlation')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = len(X_test[0])\n",
    "print(n_components)\n",
    "\n",
    "pca = PCA(n_components=n_components)  # create a PCA object\n",
    "X_test_pca = pca.fit_transform(X_test)  # do the math\n",
    "\n",
    "# project back\n",
    "X_test_pca_proj_back = pca.inverse_transform(X_test_pca)\n",
    "rec_errors = X_test - X_test_pca_proj_back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_errors_pd = pd.DataFrame(rec_errors, columns=features_normalized.columns)\n",
    "rec_errors_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_merged = pd.concat(\n",
    "    [rec_errors_pd.reset_index(), group_test.reset_index()], axis=1)\n",
    "task_2_merged = task_2_merged.drop([\"index\"], axis=1)\n",
    "task_2_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_rec_error = task_2_merged.loc[task_2_merged[\"SEX\"] == 1].mean().mean()\n",
    "group2_rec_error = task_2_merged.loc[task_2_merged[\"SEX\"] == 2].mean().mean()\n",
    "group3_rec_error = task_2_merged.loc[task_2_merged[\"RAC1P\"] == 1].mean().mean()\n",
    "group4_rec_error = task_2_merged.loc[task_2_merged[\"RAC1P\"] == 2].mean().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Group 1 reconstruction error mean: {group1_rec_error}\")\n",
    "print(f\"Group 2 reconstruction error mean: {group2_rec_error}\")\n",
    "print(f\"Group 3 reconstruction error mean: {group3_rec_error}\")\n",
    "print(f\"Group 4 reconstruction error mean: {group4_rec_error}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import null_space\n",
    "from scipy.linalg import eig\n",
    "\n",
    "\n",
    "def fair_pca(X, Z):\n",
    "    SEX_minus_mean = Z[\"SEX\"] - Z[\"SEX\"].mean()\n",
    "    RAC1P_minus_mean = Z[\"RAC1P\"] - Z[\"RAC1P\"].mean()\n",
    "    _Z = Z.copy()\n",
    "    _Z[\"SEX\"] = SEX_minus_mean\n",
    "    _Z[\"RAC1P\"] = RAC1P_minus_mean\n",
    "\n",
    "    R = null_space(_Z.to_numpy().T.dot(X))\n",
    "\n",
    "    rtx = R.T.dot(X.T)\n",
    "    rtxxt = rtx.dot(X)\n",
    "    rtxxtr = rtxxt.dot(R)\n",
    "\n",
    "    eigenvectors, eigenvalues = eig(rtxxtr)\n",
    "    L = eigenvalues\n",
    "    U = R.dot(L)\n",
    "    X_prim = X.dot(U)\n",
    "\n",
    "    return X_prim, U, _Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prim, U, _Z = fair_pca(X_train, group_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_pca_columns = []\n",
    "for i in range(len(X_prim[0])):\n",
    "    fair_pca_columns.append(f\"F_PC{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_pca_no_protected = pd.DataFrame(X_prim, columns=fair_pca_columns)\n",
    "fair_pca_no_protected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3_merged = pd.concat(\n",
    "    [fair_pca_no_protected.reset_index(), _Z.reset_index()], axis=1)\n",
    "task_3_merged = task_3_merged.drop([\"index\"], axis=1)\n",
    "task_3_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = calculate_pvalues(task_3_merged)\n",
    "p_values = p_values.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_filtered_relevant(task_3_merged.corr(method='pearson')[\n",
    "                          ['SEX', 'RAC1P']], p_values[['SEX', 'RAC1P']], corrected_alpha, 'Pearson Correlation')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prim_pca, U, _Z = fair_pca(X_test, group_test)\n",
    "X_prim_pca.shape\n",
    "# project back\n",
    "\n",
    "X_test_fair_pca_proj_back = np.dot(X_prim_pca, U.T)\n",
    "rec_errors = X_test - X_test_fair_pca_proj_back\n",
    "rec_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_errors_fair_pd = pd.DataFrame(\n",
    "    rec_errors, columns=features_normalized.columns)\n",
    "rec_errors_fair_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_4_merged = pd.concat(\n",
    "    [rec_errors_fair_pd.reset_index(), group_test.reset_index()], axis=1)\n",
    "task_4_merged = task_4_merged.drop([\"index\"], axis=1)\n",
    "task_4_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_rec_error = task_4_merged.loc[task_4_merged[\"SEX\"] == 1].mean().mean()\n",
    "group2_rec_error = task_4_merged.loc[task_4_merged[\"SEX\"] == 2].mean().mean()\n",
    "group3_rec_error = task_4_merged.loc[task_4_merged[\"RAC1P\"] == 1].mean().mean()\n",
    "group4_rec_error = task_4_merged.loc[task_4_merged[\"RAC1P\"] == 2].mean().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Group 1 reconstruction error mean: {group1_rec_error}\")\n",
    "print(f\"Group 2 reconstruction error mean: {group2_rec_error}\")\n",
    "print(f\"Group 3 reconstruction error mean: {group3_rec_error}\")\n",
    "print(f\"Group 4 reconstruction error mean: {group4_rec_error}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fair_pca, _, _ = fair_pca(X_test, group_test)\n",
    "X_test_fair_pca  # 52 fair PCA components, they suggested using only first 30\n",
    "# X_test_fair_pca is without protected groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
