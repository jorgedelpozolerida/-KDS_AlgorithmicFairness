{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "Authors: Kamil Kojs, János Máté and Jorge del Pozo Lérida"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "US Census data from https://github.com/zykls/folktables. \n",
    "\n",
    "We use data of individuals from the state California in 2018. \n",
    "More details on the dataset can be found in the accompanying\n",
    "paper at https://arxiv.org/pdf/2108.04884.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables.acs import adult_filter\n",
    "from folktables import ACSDataSource\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "feature_names = ['AGEP', # Age\n",
    "                 \"CIT\", # Citizenship status\n",
    "                 'COW', # Class of worker\n",
    "                 \"ENG\", # Ability to speak English\n",
    "                 'SCHL', # Educational attainment\n",
    "                 'MAR', # Marital status\n",
    "                 \"HINS1\", # Insurance through a current or former employer or union\n",
    "                 \"HINS2\", # Insurance purchased directly from an insurance company\n",
    "                 \"HINS4\", # Medicaid\n",
    "                 \"RAC1P\", # Recoded detailed race code\n",
    "                 'SEX']\n",
    "\n",
    "target_name = \"PINCP\" # Total person's income\n",
    "\n",
    "def data_processing(data, features, target_name:str, threshold: float = 35000):\n",
    "    df = data\n",
    "    ### Adult Filter (STARTS) (from Foltktables)\n",
    "    df = df[~df[\"SEX\"].isnull()]\n",
    "    df = df[~df[\"RAC1P\"].isnull()]\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    ### Adult Filter (ENDS)\n",
    "    ### Groups of interest\n",
    "    sex = df[\"SEX\"].values\n",
    "    ### Target\n",
    "    df[\"target\"] = df[target_name] > threshold\n",
    "    target = df[\"target\"].values\n",
    "    df = df[features + [\"target\", target_name]] ##we want to keep df before one_hot encoding to make Bias Analysis\n",
    "    df_processed = df[features].copy()\n",
    "    cols = [ \"HINS1\", \"HINS2\", \"HINS4\", \"CIT\", \"COW\", \"SCHL\", \"MAR\", \"SEX\", \"RAC1P\"]\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=False, columns=cols, drop_first=True)\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=True, columns=[\"ENG\"], drop_first=True)\n",
    "    return df_processed, df, target, sex\n",
    "\n",
    "data, data_original, target, group = data_processing(acs_data, feature_names, target_name)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    data, target, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>HINS1_2</th>\n",
       "      <th>HINS2_2</th>\n",
       "      <th>HINS4_2</th>\n",
       "      <th>CIT_2</th>\n",
       "      <th>CIT_3</th>\n",
       "      <th>CIT_4</th>\n",
       "      <th>CIT_5</th>\n",
       "      <th>COW_2.0</th>\n",
       "      <th>COW_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>RAC1P_4</th>\n",
       "      <th>RAC1P_5</th>\n",
       "      <th>RAC1P_6</th>\n",
       "      <th>RAC1P_7</th>\n",
       "      <th>RAC1P_8</th>\n",
       "      <th>RAC1P_9</th>\n",
       "      <th>ENG_2.0</th>\n",
       "      <th>ENG_3.0</th>\n",
       "      <th>ENG_4.0</th>\n",
       "      <th>ENG_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "      <td>195665.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.734914</td>\n",
       "      <td>0.348913</td>\n",
       "      <td>0.865377</td>\n",
       "      <td>0.856689</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.177078</td>\n",
       "      <td>0.135262</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.080571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.167168</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.116490</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.087231</td>\n",
       "      <td>0.056183</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.577916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.884622</td>\n",
       "      <td>0.476628</td>\n",
       "      <td>0.341321</td>\n",
       "      <td>0.350391</td>\n",
       "      <td>0.044772</td>\n",
       "      <td>0.113194</td>\n",
       "      <td>0.381736</td>\n",
       "      <td>0.342004</td>\n",
       "      <td>0.256157</td>\n",
       "      <td>0.272176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.373127</td>\n",
       "      <td>0.056965</td>\n",
       "      <td>0.320812</td>\n",
       "      <td>0.200450</td>\n",
       "      <td>0.282174</td>\n",
       "      <td>0.230275</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>0.493893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AGEP        HINS1_2        HINS2_2        HINS4_2  \\\n",
       "count  195665.000000  195665.000000  195665.000000  195665.000000   \n",
       "mean       42.734914       0.348913       0.865377       0.856689   \n",
       "std        14.884622       0.476628       0.341321       0.350391   \n",
       "min        17.000000       0.000000       0.000000       0.000000   \n",
       "25%        30.000000       0.000000       1.000000       1.000000   \n",
       "50%        42.000000       0.000000       1.000000       1.000000   \n",
       "75%        55.000000       1.000000       1.000000       1.000000   \n",
       "max        94.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               CIT_2          CIT_3          CIT_4          CIT_5  \\\n",
       "count  195665.000000  195665.000000  195665.000000  195665.000000   \n",
       "mean        0.002009       0.012981       0.177078       0.135262   \n",
       "std         0.044772       0.113194       0.381736       0.342004   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             COW_2.0        COW_3.0  ...        RAC1P_4        RAC1P_5  \\\n",
       "count  195665.000000  195665.000000  ...  195665.000000  195665.000000   \n",
       "mean        0.070600       0.080571  ...       0.000066       0.002300   \n",
       "std         0.256157       0.272176  ...       0.008151       0.047902   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "75%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "             RAC1P_6        RAC1P_7        RAC1P_8        RAC1P_9  \\\n",
       "count  195665.000000  195665.000000  195665.000000  195665.000000   \n",
       "mean        0.167168       0.003256       0.116490       0.041939   \n",
       "std         0.373127       0.056965       0.320812       0.200450   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             ENG_2.0        ENG_3.0        ENG_4.0        ENG_nan  \n",
       "count  195665.000000  195665.000000  195665.000000  195665.000000  \n",
       "mean        0.087231       0.056183       0.019227       0.577916  \n",
       "std         0.282174       0.230275       0.137321       0.493893  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: Classifiers and fairness considerations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics  \n",
    "\n",
    "# Scale training and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {}\n",
    "\n",
    "# RandomForest\n",
    "rf_model = RandomForestClassifier(n_estimators = 100)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "models['RandomForest'] = [rf_model, y_pred_rf]\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "learning_rate = 0.5\n",
    "gb_model = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "gb_model.fit(X_train_scaled,y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "models['GradientBoostingClassifier'] = [gb_model, y_pred_gb]\n",
    "\n",
    "# # Support Vector Machine\n",
    "# svm_model = SVC()\n",
    "# svm_model.fit(X_train_scaled, y_train)\n",
    "# black_models.append(svm_model)\n",
    "\n",
    "# TO DO:\n",
    "# - Apply onehot encoding \n",
    "# - Extra scaling/different required?\n",
    "# - Feature engieering required?\n",
    "# - Add predicition of y_pred\n",
    "# - SVMtaking too long\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White-box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester2/Algorithmic_Fairness_Accountability_Ethics/venv_algofair/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# LogisticRegression\n",
    "logreg_model = LogisticRegression(random_state=16)\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "y_pred_logreg = logreg_model.predict(X_test_scaled)\n",
    "models['LogisticRegression'] = [logreg_model, y_pred_logreg]\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train,y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "models['DecisionTree'] = [dt_model, y_pred_dt]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairnessmetrics(model):\n",
    "    # Code for calculating fairnes metrics\n",
    "\n",
    "    return None, None, None\n",
    "def plot_fairnessmetrics(model):\n",
    "    # Code for plotting results of fairness data\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "GradientBoostingClassifier\n",
      "LogisticRegression\n",
      "DecisionTree\n"
     ]
    }
   ],
   "source": [
    "statisticalparities = []\n",
    "equalized_odds = []\n",
    "equalityofoutcomes = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    statisticalparity, equalizedodd, eq_of_outcome = get_fairnessmetrics(model)\n",
    "\n",
    "    # Make plots and save into object\n",
    "\n",
    "    # Append metrics and plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countermeasures for fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change classification pipeline to fulfill ONE fairness criteria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2: Explaining white-box models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3: Model-agnostic explanations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task4: Reflection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_algofair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e6df175d188156a6f4c4899a9dbad9dfdc02f2af6c52c77b83a64fd2f1ec586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
